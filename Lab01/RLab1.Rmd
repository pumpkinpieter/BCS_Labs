---
title: "R Coding Lab Part 1"
output: rmdformats::html_docco
---

```{r setup, include=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Complete the following lab as a group. This document should exist in your GitHub repo while you're working on it. Your code should be heavily commented so someone reading your code can follow along easily. See the first code snippet below for an example of commented code.**

**Here's the catch: For any given problem, the person writing the code should not be the person commenting that code, and every person must both code AND comment at least one problem in this lab (you decide how to split the work). This will involve lots of pushing and pulling through Git, and you may have to resolve conflicts if you're not careful! Refer to last Thursday's class notes for details on conflict resolution.**

**Use only tools covered on Tuesday's lecture (including those discussed on the lecture recording)**.

# Playing With Cherry Blossom Race Data

1) First load the data, which is saved as a .RData file called `CBdata.1_10.RData`. This is the first ten years' worth of Cherry Blossom Race data. Pull out the data associated with 1976 and store it as a data frame called `dat.76`. Remove the column `Pis/Tis`. 


```{r import_data}
#Loading the cherry blossom data. (this is an example of a properly commented line of code)
load("CBdata.1_10.RData") 

#Pull out the data associated with 1976 and store it as a data frame called `dat.76`
for(i in 1:length(CBdata.1_10)){
if(unique(CBdata.1_10[[i]]["Year"])==1976){
   index = i
}
  
}
print(index)

dat.76 = CBdata.1_10[[index]]

#Now write code to remove the specified column
drop <- c("PiS/TiS")
dat.76= dat.76[,!(names(dat.76) %in% drop)]

```


2) The function `summary()` is useful for learning basic facts about vectors, data frames, and many other R objects. Use this function to find the mean and median recorded ages in 1976. 

```{r summary}
print("Summary of recorded ages in 1976:")
summary(dat.76$Age)

print(paste0("Mean recorded ages in 1976 = ",summary(dat.76$Age)["Mean"]))
print(paste0("Median recorded ages in 1976 = ",summary(dat.76$Age)["Median"]))

```


3) You might have noticed that a number of age values are missing (i.e. `NA`). Your next goal is to write a loop that removes observations that don't have age data.  
Hints:  
- The `is.na()` function may be useful. Use the `?is.na` command to pull up documentation on this function. It might be helpful to play around with a toy example like `c(1,2,NA,3)` to make sure you understand this new function!  
- Depending on how you write your code, you may need to negate a logical vector using `!`. Ex: `!c(TRUE, TRUE, FALSE)` is identical to `c(FALSE, FALSE, TRUE)`.

```{r filter_missing_age_loop}
#create a vector with index of rows with missing age values

drop_rows = c()
for(i in 1:nrow(dat.76)){
  #check if ith row has missing age
  if(is.na(dat.76$Age[i])){
    #append i to drop_rows
    drop_rows= append(drop_rows,i)
  }
}
print(length(drop_rows))

#drop all rows with indices %in% drop_rows
dat.76.clean <- dat.76[-drop_rows,]

```

 4) Now use vectorization and the `is.na()` function to accomplish the same thing as the loop above.  
How to check your work: If your loop produced a data frame called "dat.76.clean" and the vectorization approach produced a data frame called `dat.76.clean2`, the `identical(dat.76.clean,dat.76.clean2)` should return `TRUE`.

```{r filter_missing_age_vectorization}

#subset all rows from dat.76 excluding those with missing age
dat.76.clean2 = dat.76[!is.na(dat.76$Age),]

#check 
identical(dat.76.clean,dat.76.clean2)
```

5) Filtering out missing age data could be useful when dealing with other years. With this in mind, turn your filter loop or vectorization approach into a function. You should be able to use the function like this: `dat.76.clean <- filter.func(dat.76)`.  
When you have a function written, run it on the 1976 data and use identical() to verify that your function and the first loop you wrote are doing the same thing.

```{r filter_func}

select.data.yr<- function(yrs){
                          #Step1 :Pull out the data associated with year = yrs
                          for(i in 1:length(CBdata.1_10)){
                              if(unique(CBdata.1_10[[i]]["Year"])[[1]]==yrs){
                                  index = i
                                    }
                                    }
                                    print(index)

                          data.yr= CBdata.1_10[[index]]

                          return(data.yr)
                          }

                          
filter.func<-function(data.year){
  
                          #Step2 :Now write code to remove the specified column
                          drop <- c("PiS/TiS")
                          data.year= data.year[,!(names(data.year) %in% drop)]
                          
                          #remove rows with missing age data
                          data.clean = data.year[!is.na(data.year$Age),]
                          
                          #return clean data set
                          return(data.clean)
                          }
#Calling function 'select.data.yr' to filter out records for the year 1976 .
#Calling function 'filter.func' rows with missing age data for the year 1976 
dat.76.func <- select.data.yr(1976)
dat.76.func.clean <- filter.func(dat.76.func)

#Check
identical(dat.76.func.clean,dat.76.clean)


```

6) Next, write a loop that combines all of the data from `CBdata.1_10` into one cleaned data frame. Make sure your final data frame has neither the `Pis/Tis` column nor `NA` Age values.  
Use the `identical()` function to verify that the 1976 data in this larger cleaned data set is the same as the cleaned version of `dat.76`. 

```{r combine_dat}
#Check if each element of dataframe has unique year
Check = TRUE

#Combines all of the data from `CBdata.1_10`
data.all = CBdata.1_10[[1]]
for(i in 2:length(CBdata.1_10)){
  
    #Check if each element of dataframe has unique year
    if(length(unique(CBdata.1_10[[i]]["Year"]))>1){
      Check = FALSE
    }
   
   #Append the data for 'Year=CBdata.1_10[[i]]$Year'  to data.all
    data.all=rbind.data.frame(data.all,CBdata.1_10[[i]])
}

#Check class
class(data.all)

data.all.clean <- filter.func(data.all)
#Cleaning the data frame

data.76.6 = data.all.clean[data.all.clean["Year"]==1976,]

```

7) Now that you have the combined data set for these 10 years, let's do some basic exploration:  

a) How does the average of the recorded ages in 1976 compare to that same average over the entire `CBdata.1_10` data set?  
```{r 7a}
print(paste0("Mean recorded ages in 1976 = ",summary(dat.76$Age)["Mean"]))
print(paste0("Mean recorded ages in entire CBdata.1_10 = ",summary(data.all.clean$Age)["Mean"]))
print("Therefore, average of the recorded ages in 1976 is less than the average of the recorded ages in the entire data")
```

b) Recall that the `CBdata.1_10` contains the first ten year's worth of cherry blossom race data. How does the average participant age over the first five years compare to the average age over years 6-10?
```{r 7b}
print("Years in cherry blossom data:")
print(unique(data.all.clean$Year))
print(paste0("Average participant age over the first five years  = ",mean(data.all.clean[data.all.clean$Year<=1976,"Age"])))
print(paste0("Average participant age over the last five years  = ",mean(data.all.clean[data.all.clean$Year>1976,"Age"])))
```
# Playing with the indoor positioning system data

The `IPS_sampledata` data set contains a fraction of the indoor positioning system data for 15 randomly sampled locations.This data set is loaded into memory using the chunk of R code below, complete the following exercises. 

```{r eval=T, echo=T}
# loads data set IPS_sampledata
load("IPS_portion.RData")
```

### Variable dictionary

- `time`: timestamp in milliseconds since midnight 01/01/1970 UTC

- `scanMac`: MAC address of the scanning device (this is a handheld device)

- `posX`, `posY` and `posZ`: the (x, y, z) physical coordinate of the scanning device

- `orientation`: degree orientation of the user carrying the scanning device in degrees

- `mac`: MAC address of an access point

- `signal`: signal strength in dBm (Decibel-milliwatts)

- `channel`: the channel frequency

- `type`: type of device (access point = 3, device in adhoc mode = 1)

### Let's clean up the data a bit

1. First apply the `summary` function to the `IPS_data` to get a sense of what is available in that data frame. 

```{r}
summary(IPS_sampledata)
```

2. Identify variables that need any `class` conversion. Attempting to avoid code-replication as much as possible, convert these variables into the correct class type.

##convert signal, posx, posy and posz

```{r class_conversion}
#check structure of IPS_sampledata before applying any conversions
str(IPS_sampledata)

# convert "posX","posY","posZ","signal","orientation","time" to numeric
IPS_sampledata[,c("posX","posY","posZ","signal","orientation","time")]=lapply(IPS_sampledata[,c("posX","posY","posZ","signal","orientation","time")],as.numeric)

str(IPS_sampledata)
```

3. Because we only want data relative to access points, remove observations that correspond to any other type of device.

```{r  remove_type1}
#type of device (access point = 3, device in adhoc mode = 1). So we keep only the devices with type =3
IPS.clean   = IPS_sampledata[IPS_sampledata$type==3,]

#Check
unique(IPS.clean$type)

```

4. Assess if there are any variables that provide redundant or no information. If so, remove them from the data frame.
```{r  remove_var_channel}

#'posz' is always zero. 'type' is always 3. 'Channel' is never used.
drop_IPS <- c("channel","type")
IPS.clean= IPS.clean[,!(names(IPS.clean) %in% drop_IPS)]


```
5. Note that the `time` variable is in milliseconds.  Transform it into seconds and then convert its class into a time format using the function `as.POSIXct`.
```{r transform_time}

#Convert time to seconds from milliseconds
IPS.clean$time = IPS.clean$time/1000
IPS.clean$time = as.POSIXct(IPS.clean$time, origin = "1970-01-01", tz = "UTC")
```

### Examining the data more closely

1. Create the function `tally_mac` whose only input is the MAC address of an access point, and returns the number of observations found in the data set for it.

```{r  tally_mac}
tally_mac = function(mac_address) {
  return(nrow(IPS.clean[IPS.clean$mac == mac_address,]))
}

#Test
test_mac = "00:14:bf:b1:97:8a"
print(tally_mac(test_mac))

```

2. Use the function `unique` to identify the unique levels for `mac` found in the data set. 

```{r  unique_mac}

unique(IPS.clean$mac)

```
3. Using an approach learned in class together with `tally_mac`, tally the  number of observations for all access points in the data. While the researchers did their best to clean their data, some noise was introduced by access points on other floors.  Based on the number of counts, identify and remove likely suspects for access points read by mistake.

```{r remove_suspect_access_points}

# identify likely suspects for access points
a_pts = unique((IPS.clean$mac))

mac_counts = data.frame(matrix(vector(), length(a_pts), 2,
                dimnames=list(c(), c("mac_address","count"))),
                stringsAsFactors=F)

for(i in 1:(length(a_pts))){
  print(a_pts[i])
  print(tally_mac(a_pts[i]))
  mac_counts$mac_address[i] = a_pts[i]
  mac_counts$count[i] = tally_mac(a_pts[i])
}

print("Most of the access points have count of order of ten thousand. However there are four access points with very low count and seem inconsistent with the remaining data")

print("Zccess points with very low count(<10000) are: ")
mac_counts[mac_counts$count <10000,]
suspect_access = as.vector(mac_counts[mac_counts$count <10000,1])

# remove likely suspects for access points
IPS.clean2 = IPS.clean[!(IPS.clean$mac  %in% suspect_access),]
```
4.  The orientation of the hand-held device considered was supposed to be exactly set to the 8 angles from 0-315 in increments of 45 degrees (360 is equivalent to 0). However, in practice the measured orientations were close to the 8 expected but had some error, so we'll need to group them.  Develop and apply a function to recode the orientation values as one of 0, 45, 90, 135, 180, 225, 270, 315. Call the recoded orientation variable `rec_orient`.

```{r rec_orient}
reorient = function(orient) {
            r_orient = as.integer(round(orient/45)*45)
            r_orient[r_orient  == 360] = 0
            print(class(r_orient))
            return(r_orient)
            }

IPS.clean2$rec_orient = reorient(IPS.clean2$orientation)
unique(IPS.clean2$rec_orient)
```

5. Create the function `signal_summary` that takes as inputs a location (`posX`, `posY`, `posZ`), an orientation (`rec_orient`) and an access point id (`mac`).  The function must identify and subset the rows in `IPS_sampledata` corresponding to this unique combination, then it must calculate and return the mean and standard deviation for the corresponding signal strengths. 

```{r signal_summary}

inpt1.names <- c("posX", "posY", "posZ", "rec_orient","mac")
inpt1 <- NULL
inpt1[inpt1.names] <- list(NULL)


signal_summary <- function(inpt_list){
                        
                          
                        #Subset dataframe
                         signal_df = IPS.clean2[c(IPS.clean2$posX==inpt_list$posX & IPS.clean2$posY==inpt_list$posY & IPS.clean2$posZ==inpt_list$posZ & IPS.clean2$rec_orient == inpt_list$rec_orient & IPS.clean2$mac == inpt_list$mac),]
                         
                         #mean and standard deviation for the corres. signal strengths
                         mean_signal = mean(signal_df$signal,na.rm = TRUE)
                         std_dev_signal = sd(signal_df$signal,na.rm = TRUE)
                         identifier = paste0("posX_",unique(signal_df$posX),"_posY_",unique(signal_df$posY),"_posZ_",unique(signal_df$posZ),"_rec_orient_",unique(signal_df$rec_orient),"_mac_",unique(signal_df$mac))
                         signal_strngth = c(identifier,mean_signal,std_dev_signal)
                          
                         return(signal_strngth)

}


inpt1[[1]]= list(posX =2,posY= 13,posZ = 0,rec_orient = 315,mac = "00:14:bf:b1:97:8a")
inpt1[[2]]= list(posX =2,posY= 13,posZ = 0,rec_orient = 45,mac = "00:14:bf:b1:97:8a")
signal_summary(inpt1[[2]])
```
6.  Create a list where each entry corresponds to a named list including unique combination of a location, an orientation, and an access point.  Use this list in combination with `lapply` and `signal_summary` to generate a summary of signals for each unique combination. `Hint`: you may want to create a new variable with a unique identifier that combines location, `rec_orient` and `mac` to make your life simpler.  One way to go about this is using the `paste` function (see `?paste` for help on its use) with these variables in a row-by-row fashion.


```{r}

#Filter unique combination of a location, an orientation, and an access point
df = unique(IPS.clean2[,c("posX","posY","posZ","rec_orient","mac")])

#create a dataframe with unique combination of a location, an orientation, and an access point
mac_orient_signal_df = data.frame(matrix(vector(), 840, 5,
                dimnames=list(c(), c("posX","posY","posZ","rec_orient","mac"
                                     #,"avg_signal","sd_signal"
                                     ))),
                stringsAsFactors=F)

mac_orient_signal_df[,c("posX","posY","posZ","rec_orient","mac")]<- df[,c("posX","posY","posZ","rec_orient","mac")]

#convert the dataframe to a list of lists with each. Each elemnt in the list is a list of  data points for one row of the dataframe
mac_orient_signal_list <- split(mac_orient_signal_df,seq(nrow(mac_orient_signal_df))) 

#use lapply function and signal_summary to generate a summary of signals for each unique combination
summary_avg= lapply(mac_orient_signal_list,signal_summary)
print(summary_avg)
```

